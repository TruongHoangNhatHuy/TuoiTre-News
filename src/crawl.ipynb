{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from enum import Enum\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.remote.webelement import WebElement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileHandler():\n",
    "    @staticmethod\n",
    "    def is_file_empty(file_name: str) -> bool:\n",
    "        \"\"\"Return True if file is empty\n",
    "\n",
    "        Args: \n",
    "            - file_name: file's name that is needed to be check\n",
    "        \"\"\"\n",
    "        return os.stat(file_name).st_size == 0\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def write_to_csv(rows: list, file_name: str) -> None:\n",
    "        header = ['Title', 'Content', 'Date', 'Url', 'Summary']\n",
    "        data = pd.DataFrame(rows, index=None, columns=header)\n",
    "\n",
    "        if FileHandler.is_file_empty(file_name):\n",
    "            data.to_csv(file_name)\n",
    "        else:\n",
    "            existed_data = pd.read_csv(file_name)\n",
    "            merged_data = pd.merge(data, existed_data, how='outer').sort_values(by='Date', axis=0, ascending=False)\n",
    "            merged_data.to_csv(file_name, index=False)\n",
    "    # def write_to_csv(rows, file_name: str) -> None:\n",
    "    #     header = ['Title', 'Content', 'Date', 'Url', 'Summary']\n",
    "    #     file = open(file_name, 'a', encoding='UTF8', newline='')\n",
    "    #     writer = csv.writer(file)\n",
    "\n",
    "    #     if FileHandler.is_file_empty(file_name):\n",
    "    #         writer.writerow(header)\n",
    "    #     for row in rows:\n",
    "    #         writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrowserOption(Enum):\n",
    "    \"\"\"Option for webbrowser\n",
    "    \"\"\"\n",
    "    EDGE = 1\n",
    "    CHROME = 2\n",
    "    FIREFOX = 3\n",
    "    SAFARI = 4\n",
    "\n",
    "class TuoiTre_Crawler:\n",
    "    @staticmethod\n",
    "    def get_driver(browser_option: BrowserOption = BrowserOption.EDGE):\n",
    "        \"\"\"Return driver depended on BrowserOption Enum\n",
    "        \n",
    "        Args:\n",
    "            - browser_option: the option of browser's driver\n",
    "        \"\"\"\n",
    "        if browser_option == BrowserOption.EDGE:\n",
    "            options = webdriver.EdgeOptions()\n",
    "            options.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "            options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})\n",
    "            return webdriver.ChromiumEdge(options=options)\n",
    "        elif browser_option == BrowserOption.FIREFOX:\n",
    "            return webdriver.Firefox()\n",
    "        elif browser_option == BrowserOption.SAFARI:\n",
    "            return webdriver.Safari()       \n",
    "        else:\n",
    "            options = webdriver.ChromeOptions()\n",
    "            options.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "            options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})\n",
    "            return webdriver.Chrome(options=options)  \n",
    "        \n",
    "    def __init__(self, browser_option: BrowserOption, folder_to_save: str, category_url: dict) -> None:\n",
    "        \"\"\"Create a new instance of crawler\n",
    "        \n",
    "        Args:\n",
    "            - browser_option: the option of browser's driver\n",
    "            - folder_to_save: folder to save data crawled\n",
    "            - category_url: a dictionary which key=filename, value=category url\n",
    "        \"\"\"\n",
    "        self.driver = TuoiTre_Crawler.get_driver(browser_option)\n",
    "        # self.url_file = url_file\n",
    "        self.folder_to_save = folder_to_save\n",
    "        self.category_url = category_url\n",
    "\n",
    "    def crawl(self, url: str):\n",
    "        \"\"\"Crawl data from single url\n",
    "        \n",
    "        Args:\n",
    "            - url: a news url\n",
    "        \"\"\"\n",
    "        self.driver.get(url)\n",
    "\n",
    "        title_selector = \"#main-detail > .article-title\"\n",
    "        contents_selector = \"div.detail-content.afcbc-body > :not(.VCSortableInPreviewMode, #InreadPc)\"\n",
    "        date_selector = \"#main-detail > div.detail-top > div.detail-time\"\n",
    "        summary_selector = \"#main-detail > .detail-sapo\"\n",
    "        \n",
    "        title = self.driver.find_element(By.CSS_SELECTOR, title_selector)\n",
    "        contents = self.driver.find_elements(By.CSS_SELECTOR, contents_selector)\n",
    "        date = self.driver.find_element(By.CSS_SELECTOR, date_selector)\n",
    "        summary = self.driver.find_element(By.CSS_SELECTOR, summary_selector)\n",
    "\n",
    "        title = title.text[:title.text.find('\\n')]\n",
    "        joined_content = \" \".join(x.text for x in contents)\n",
    "        return (title, joined_content, date.text, summary.text)\n",
    "\n",
    "    def news_from_category(self, filename: str, url: str):\n",
    "        \"\"\"Get news URL from category page\n",
    "        \n",
    "        Args:\n",
    "            - filename: file to save data\n",
    "            - url: a category page url\n",
    "        \"\"\"\n",
    "        self.driver.get(url)\n",
    "\n",
    "        focus_main_selector = \"div.list__focus-main a.box-category-link-title\"\n",
    "        focus_main = self.driver.find_elements(By.CSS_SELECTOR, focus_main_selector)\n",
    "\n",
    "        listing_main_selector = \"div.list__listing-main a.box-category-link-title\"\n",
    "        listing_main = self.driver.find_elements(By.CSS_SELECTOR, listing_main_selector)\n",
    "\n",
    "        news_urls = [url.get_property('href') for url in focus_main]\n",
    "        news_urls.extend([url.get_property('href') for url in listing_main])\n",
    "        \n",
    "        rows = []\n",
    "        for news_url in news_urls:\n",
    "            try:\n",
    "                (title, joined_content, date, summary) = self.crawl(news_url)\n",
    "                rows.append([title, joined_content, date, news_url, summary])\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        FileHandler.write_to_csv(rows, os.path.join(self.folder_to_save, filename))\n",
    "        print(\"Crawled\", len(rows), \"from\", url)\n",
    "        return len(rows)\n",
    "\n",
    "    def start_crawl(self):\n",
    "        count = 0\n",
    "        for file, url in self.category_url.items():\n",
    "            count += self.news_from_category(file, url)\n",
    "\n",
    "        print(\"Done! Crawled\", count)\n",
    "        self.driver.quit()\n",
    "\n",
    "    def data_summary(self, verbose=False):\n",
    "        header = ['Title', 'Content', 'Date', 'Url', 'Summary']\n",
    "        total = pd.DataFrame(columns=header)\n",
    "        for file, url in self.category_url.items():\n",
    "            data = pd.read_csv(os.path.join(self.folder_to_save, file))\n",
    "            total = pd.merge(data, total, how='outer')\n",
    "            print('Data:', file)\n",
    "            print(data.info(verbose=verbose))\n",
    "            print('=====================================')\n",
    "        print('Total:')\n",
    "        print(total.info(verbose=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawled 26 from https://tuoitre.vn/kinh-doanh.htm\n",
      "Crawled 29 from https://tuoitre.vn/cong-nghe.htm\n",
      "Crawled 25 from https://tuoitre.vn/du-lich.htm\n",
      "Crawled 27 from https://tuoitre.vn/van-hoa.htm\n",
      "Crawled 28 from https://tuoitre.vn/giai-tri.htm\n",
      "Crawled 28 from https://tuoitre.vn/the-thao.htm\n",
      "Crawled 29 from https://tuoitre.vn/giao-duc.htm\n",
      "Done! Crawled 192\n"
     ]
    }
   ],
   "source": [
    "category_url = {\n",
    "    \"tuoitre_kinhdoanh.csv\": \"https://tuoitre.vn/kinh-doanh.htm\",\n",
    "    \"tuoitre_congnghe.csv\": \"https://tuoitre.vn/cong-nghe.htm\",\n",
    "    \"tuoitre_dulich.csv\": \"https://tuoitre.vn/du-lich.htm\",\n",
    "    \"tuoitre_vanhoa.csv\": \"https://tuoitre.vn/van-hoa.htm\",\n",
    "    \"tuoitre_giaitri.csv\": \"https://tuoitre.vn/giai-tri.htm\",\n",
    "    \"tuoitre_thethao.csv\": \"https://tuoitre.vn/the-thao.htm\",\n",
    "    \"tuoitre_giaoduc.csv\": \"https://tuoitre.vn/giao-duc.htm\"\n",
    "}\n",
    "\n",
    "crawler = TuoiTre_Crawler(BrowserOption.EDGE, folder_to_save='./dataset', category_url=category_url)\n",
    "crawler.start_crawl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: tuoitre_kinhdoanh.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 105 entries, 0 to 104\n",
      "Columns: 5 entries, Title to Summary\n",
      "dtypes: object(5)\n",
      "memory usage: 4.2+ KB\n",
      "None\n",
      "=====================================\n",
      "Data: tuoitre_congnghe.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45 entries, 0 to 44\n",
      "Columns: 5 entries, Title to Summary\n",
      "dtypes: object(5)\n",
      "memory usage: 1.9+ KB\n",
      "None\n",
      "=====================================\n",
      "Data: tuoitre_dulich.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Columns: 5 entries, Title to Summary\n",
      "dtypes: object(5)\n",
      "memory usage: 2.1+ KB\n",
      "None\n",
      "=====================================\n",
      "Data: tuoitre_vanhoa.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59 entries, 0 to 58\n",
      "Columns: 5 entries, Title to Summary\n",
      "dtypes: object(5)\n",
      "memory usage: 2.4+ KB\n",
      "None\n",
      "=====================================\n",
      "Data: tuoitre_giaitri.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 87 entries, 0 to 86\n",
      "Columns: 5 entries, Title to Summary\n",
      "dtypes: object(5)\n",
      "memory usage: 3.5+ KB\n",
      "None\n",
      "=====================================\n",
      "Data: tuoitre_thethao.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110 entries, 0 to 109\n",
      "Columns: 5 entries, Title to Summary\n",
      "dtypes: object(5)\n",
      "memory usage: 4.4+ KB\n",
      "None\n",
      "=====================================\n",
      "Data: tuoitre_giaoduc.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 102 entries, 0 to 101\n",
      "Columns: 5 entries, Title to Summary\n",
      "dtypes: object(5)\n",
      "memory usage: 4.1+ KB\n",
      "None\n",
      "=====================================\n",
      "Total:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 545 entries, 0 to 544\n",
      "Columns: 5 entries, Title to Summary\n",
      "dtypes: object(5)\n",
      "memory usage: 21.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "crawler.data_summary(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giá vàng miếng SJC cao kỷ lục: 83,5 triệu đồng/lượng\n",
      "1\n",
      "09/04/2024 12:15 GMT+7\n",
      "Hôm nay 9-4, giá vàng miếng SJC đã lần đầu chạm tới mức kỷ lục: 83,5 triệu đồng/lượng. Giá vàng nhẫn 9999 cũng xác lập đỉnh mới dù giá vàng thế giới hôm nay chỉ nhích nhẹ so với hôm qua.\n",
      "[ Lúc 12h hôm nay, giá vàng thế giới ở mức 2.345 USD/ounce, chỉ tăng khoảng 5 USD/ounce, tương đương 151.000 đồng/lượng. Quy đổi theo tỉ giá niêm yết tại ngân hàng, giá vàng thế giới tương đương 71 triệu đồng/lượng. Công ty SJC sáng nay tăng giá bán vàng miếng SJC lên mức 83 triệu đồng/lượng, tăng 600.000 đồng/lượng so với cuối ngày hôm qua. Tuy nhiên đến trưa nay, giá bán vàng miếng SJC tăng thêm 500.000 đồng/lượng, lên mức 83,5 triệu đồng/lượng. Giá mua vào cũng tăng lên mức 81,5 triệu đồng/lượng. Như vậy giá bán vàng miếng SJC đã tăng 1,6 triệu đồng/lượng chỉ sau hai ngày. Tại Công ty PNJ, giá bán vàng miếng SJC trưa nay lên đến 83,2 triệu đồng/lượng, giá mua vào lên đến 81 triệu đồng/lượng, cao hơn 200.000 đồng/lượng ở chiều bán so với hôm qua. Đáng chú ý hiện nay giá bán vàng miếng SJC tại các tiệm vàng đã bám sát với giá bán vàng miếng SJC tại các công ty lớn. Giá vàng nhẫn 9999 hôm nay cũng xác lập kỷ lục mới. Công ty DOJI tăng giá bán vàng nhẫn 9999 thêm 200.000 đồng/lượng, lên mức 75,4 triệu đồng/lượng, mua vào ở mức 73,9 triệu đồng/lượng, tăng 150.000 đồng/lượng so với cuối ngày hôm qua. Công ty SJC và PNJ hôm nay tăng mạnh giá bán vàng nhẫn 9999 do hôm qua giá mua bán vàng nhẫn tại Công ty SJC và PNJ tăng chậm hơn các công ty vàng khác. Tại Công ty SJC, giá vàng nhẫn 9999 loại 1-5 chỉ tăng lên mức 74,6 triệu đồng/lượng. Giá mua vào cũng tăng thêm 350.000 đồng/lượng, lên mức 73,2 triệu đồng/lượng. Giá vàng nhẫn 9999 niêm yết tại Công ty PNJ cũng tăng 500.000 đồng/lượng, bán ra ở mức 74,6 triệu đồng/lượng, mua vào 73,2 triệu đồng/lượng. Như vậy chỉ sau ba phiên gần nhất, mỗi lượng vàng nhẫn 9999 đã tăng thêm khoảng 2,5 triệu đồng/lượng, còn nếu tính từ đầu năm đến nay giá vàng nhẫn đã tăng hơn 10 triệu đồng/lượng. ]\n"
     ]
    }
   ],
   "source": [
    "# def crawl(url: str) -> tuple[list[WebElement], list[WebElement]]:\n",
    "#     \"\"\"Crawl data from single url\n",
    "    \n",
    "#     Args:\n",
    "#         - url: a news url\n",
    "#     \"\"\"\n",
    "#     options = webdriver.EdgeOptions()\n",
    "#     options.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "#     options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})\n",
    "#     driver = webdriver.ChromiumEdge(options=options)\n",
    "\n",
    "#     driver.get(url)\n",
    "\n",
    "#     title_selector = \"#main-detail > .article-title\"\n",
    "#     title = driver.find_element(By.CSS_SELECTOR, title_selector)\n",
    "#     print(title.text)\n",
    "\n",
    "#     date_selector = \"#main-detail > div.detail-top > div.detail-time\"\n",
    "#     date = driver.find_element(By.CSS_SELECTOR, date_selector)\n",
    "#     print(date.text)\n",
    "\n",
    "#     summary_selector = \"#main-detail > .detail-sapo\"\n",
    "#     summary = driver.find_element(By.CSS_SELECTOR, summary_selector)\n",
    "#     print(summary.text)\n",
    "\n",
    "#     content_selector = \"div.detail-content.afcbc-body > :not(.VCSortableInPreviewMode, #InreadPc)\"\n",
    "#     content = driver.find_elements(By.CSS_SELECTOR, content_selector)\n",
    "#     joined_content = \" \".join(x.text for x in content)\n",
    "#     print(\"[\", joined_content, \"]\")\n",
    "\n",
    "# crawl('https://tuoitre.vn/gia-vang-mieng-sjc-cao-ky-luc-83-5-trieu-dong-luong-20240409120819486.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def news_from_category(url: str):\n",
    "#     \"\"\"Get news URL from category page\n",
    "    \n",
    "#     Args:\n",
    "#         - url: a category page url\n",
    "#     \"\"\"\n",
    "#     options = webdriver.EdgeOptions()\n",
    "#     options.add_argument(\"--blink-settings=imagesEnabled=false\")\n",
    "#     options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2})\n",
    "#     driver = webdriver.ChromiumEdge(options=options)\n",
    "\n",
    "#     driver.get(url)\n",
    "\n",
    "#     focus_main_selector = \"div.list__focus-main a.box-category-link-title\"\n",
    "#     focus_main = driver.find_elements(By.CSS_SELECTOR, focus_main_selector)\n",
    "#     print(\"focus_main\", len(focus_main))\n",
    "#     # for e in focus_main:\n",
    "#     #     print(e.get_property('href'))\n",
    "\n",
    "#     listing_main_selector = \"div.list__listing-main a.box-category-link-title\"\n",
    "#     listing_main = driver.find_elements(By.CSS_SELECTOR, listing_main_selector)\n",
    "#     print(\"listing_main\", len(listing_main))\n",
    "#     # for e in listing_main:\n",
    "#     #     print(e.get_property('href'))\n",
    "    \n",
    "#     news_url = [url.get_property('href') for url in focus_main]\n",
    "#     news_url.extend([url.get_property('href') for url in listing_main])\n",
    "#     print(len(news_url))\n",
    "#     for e in news_url:\n",
    "#         print(e)\n",
    "\n",
    "# news_from_category('https://tuoitre.vn/the-gioi.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# def write_to_csv(rows: list, file_name):\n",
    "#     header = ['Title', 'Content', 'Date', 'Url', 'Summary']\n",
    "#     data = pd.DataFrame(rows, index=None, columns=header)\n",
    "\n",
    "#     if FileHandler.is_file_empty(file_name):\n",
    "#         data.to_csv(file_name)\n",
    "#     else:\n",
    "#         existed_data = pd.read_csv(file_name)\n",
    "#         merged_data = pd.merge(data, existed_data, how='outer').sort_values(by='Date', axis=0, ascending=False)\n",
    "#         merged_data.to_csv(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
